{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce057e8f-113f-40b0-9574-d2a267d7139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5004b8bd-b441-40c6-8c6b-de4302174ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source directory\n",
    "image_dir = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\combined_images\\VeryMildDemented\"\n",
    "image_dir1 = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\combined_images\\NonDemented\" \n",
    "image_dir2 = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\combined_images\\ModerateDemented\"\n",
    "image_dir3 = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\combined_images\\MildDemented\"\n",
    "\n",
    "\n",
    "# destination directory\n",
    "image_dir_copy = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\VeryMildDemented_1200_copy\"\n",
    "image_dir1_copy = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\NonDemented_1200_copy\" \n",
    "image_dir2_copy= r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\ModerateDemented_1200_copy\"\n",
    "image_dir3_copy = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\MildDemented_1200_copy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf7f631-59be-49d4-b0c2-8c00d8c51b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displayed: 0001b959-d622-4311-acab-84633370c892.jpg\n",
      "Displayed: 0003659d-f8db-4ce4-9230-2ba24506df68.jpg\n",
      "Displayed: 000a074f-a3a5-4c70-8c94-d7ed7bbe7018.jpg\n",
      "Displayed: 000b7abc-2404-411d-a46d-467ec55b7795.jpg\n",
      "Displayed: 000dea20-ea76-4248-a45d-4119f0bc5ccc.jpg\n"
     ]
    }
   ],
   "source": [
    "# List image files and sort them\n",
    "image_files = sorted([f for f in os.listdir(image_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "\n",
    "# Show first 5 images\n",
    "for img_file in image_files[:5]:\n",
    "    img_path = os.path.join(image_dir, img_file)\n",
    "    image = Image.open(img_path)\n",
    "    image.show()  # Opens the image\n",
    "    print(f\"Displayed: {img_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "201289c0-07ca-4de6-a070-7c431e73a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images in a directory\n",
    "image_files = sorted([f for f in os.listdir(image_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "image_files1 = sorted([f for f in os.listdir(image_dir1) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "image_files2 = sorted([f for f in os.listdir(image_dir2) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "image_files3 = sorted([f for f in os.listdir(image_dir3) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b5ec36-4a0b-47d6-ad30-a5300bb1b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the sake of no sufficient resources we will take a sample each of 1200 images\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(image_dir_copy, exist_ok=True)\n",
    "os.makedirs(image_dir1_copy, exist_ok=True)\n",
    "os.makedirs(image_dir2_copy, exist_ok=True)\n",
    "os.makedirs(image_dir3_copy, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516bcac4-95b9-426b-b469-3c04c350f802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1200 images and copied them to C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\VeryMildDemented_1200_copy.\n",
      "Selected 1200 images and copied them to C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\NonDemented_1200_copy.\n",
      "Selected 1200 images and copied them to C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\ModerateDemented_1200_copy.\n",
      "Selected 1200 images and copied them to C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\MildDemented_1200_copy.\n"
     ]
    }
   ],
   "source": [
    "# Get all image files\n",
    "\n",
    "# random.seed(42) \n",
    "\n",
    "# Select 1200 random images (same selection every time)\n",
    "selected_images = random.sample(image_files, min(1200, len(image_files1)))\n",
    "selected_images1 = random.sample(image_files1, min(1200, len(image_files1)))\n",
    "selected_images2 = random.sample(image_files2, min(1200, len(image_files2)))\n",
    "selected_images3 = random.sample(image_files3, min(1200, len(image_files3)))\n",
    "\n",
    "# Copy selected images to the new directory\n",
    "for img in selected_images:\n",
    "    shutil.copy(os.path.join(image_dir, img), os.path.join(image_dir_copy, img))\n",
    "for img in selected_images1:\n",
    "    shutil.copy(os.path.join(image_dir1, img), os.path.join(image_dir1_copy, img))\n",
    "for img in selected_images2:\n",
    "    shutil.copy(os.path.join(image_dir2, img), os.path.join(image_dir2_copy, img))\n",
    "for img in selected_images3:\n",
    "    shutil.copy(os.path.join(image_dir3, img), os.path.join(image_dir3_copy, img))\n",
    "\n",
    "print(f\"Selected {len(selected_images)} images and copied them to {image_dir_copy}.\")\n",
    "print(f\"Selected {len(selected_images1)} images and copied them to {image_dir1_copy}.\")\n",
    "print(f\"Selected {len(selected_images2)} images and copied them to {image_dir2_copy}.\")\n",
    "print(f\"Selected {len(selected_images3)} images and copied them to {image_dir3_copy}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7845588-48c1-476d-b9cb-750f2377f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9e7775b-e758-4954-ac07-f95db34a7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing & Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images\n",
    "    transforms.RandomHorizontalFlip(),  # Augment data\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cec33ee-f11f-4104-a497-1c87260663d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset (Modify path as needed)\n",
    "dataset_path = r\"C:\\Users\\UltraBook 3.1\\Desktop\\data_analysis projects\\Alzhermiers Classification\\dataset\"  # Change to your dataset directory\n",
    "train_dataset = datasets.ImageFolder(root=f\"{dataset_path}/train\", transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{dataset_path}/val\", transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2174f222-7cf5-407f-a53f-42ef7157b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fa480d4-c3eb-4dfb-a8ec-57a86d794ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CNN Model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 256)  # Adjust for image size\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(nn.ReLU()(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(nn.ReLU()(self.bn3(self.conv3(x))))\n",
    "        x = torch.flatten(x, 1)  # Flatten for FC layers\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Model Initialization\n",
    "model = CustomCNN(num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "119ba168-aa40-4412-bc54-86fe1719d636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_acc = correct / total\n",
    "        val_acc = evaluate_model(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fddac768-83d9-4045-a7d0-bf851d4cff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd4c365c-7c27-4343-a76b-e27099bf67b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 254.9478, Train Acc: 0.3944, Val Acc: 0.4752\n",
      "Epoch 2/10, Loss: 147.8894, Train Acc: 0.5531, Val Acc: 0.6138\n",
      "Epoch 3/10, Loss: 124.4842, Train Acc: 0.6238, Val Acc: 0.6358\n",
      "Epoch 4/10, Loss: 114.2363, Train Acc: 0.6585, Val Acc: 0.5846\n",
      "Epoch 5/10, Loss: 108.0062, Train Acc: 0.6727, Val Acc: 0.6421\n",
      "Epoch 6/10, Loss: 99.7400, Train Acc: 0.7002, Val Acc: 0.7063\n",
      "Epoch 7/10, Loss: 96.3553, Train Acc: 0.7115, Val Acc: 0.6110\n",
      "Epoch 8/10, Loss: 91.2330, Train Acc: 0.7273, Val Acc: 0.7044\n",
      "Epoch 9/10, Loss: 89.3631, Train Acc: 0.7367, Val Acc: 0.6965\n",
      "Epoch 10/10, Loss: 87.4135, Train Acc: 0.7425, Val Acc: 0.7342\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "train_model(model, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29936d33-9178-4c03-baa7-3c7dbdb01dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(model, loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
